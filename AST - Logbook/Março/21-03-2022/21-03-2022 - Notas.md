# Machine Learning - Google Crash Course
## Validation Set
In the previous topic, we discussed an approach to train a model in a situation where we only have one data set available. The data set would be divided into two, where one would be called the training set and the other the test set. The model would train on the training set and **evaluate** on the test set, then taking these results to tweak the model's hyperparameters (learning rate and features). 

The **caveat** on this iterative approach of training and evaluating is, **after many rounds, the procedure might cause us to implicitly fit to the peculiarities of the test set**. The more often a given test set is evaluated, the higher the risk of implicitly overfitting to that one test set is. **Let's look at a better protocol**.





---
Tags:
[[21-03-2022]], [[Notas]], [[Curso]]