# Machine Learning - Google Crash Course
## Linear Regression with a Real Dataset - Exercise
Like the previous exercise, the influence of hyperparameters will be studied in the outcome of the results: the **prediction of house prices** in California. Although, this time, the main difference is that the dataset used is real (based on 1990 census data from California). It should have the following structure:
```py
"longitude","latitude","housing_median_age","total_rooms","total_bedrooms","population","households","median_income","median_house_value"

-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000

-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000

-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.650900,85700.000000

-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.191700,73400.000000
```

The `median_house_value` feature can be scaled down by dividing it by 1000, this way the loss values are in a better range. 

A **quantile** is a bucket (unit) in quantile bucketing. **Quantile bucketing** is the act of distributing a feature's values into **buckets** in a way that each bucket has the same (or almost) number of examples.

<p align="center">
	<img src="https://developers.google.com/machine-learning/glossary/images/QuantileBucketing.svg">
</p>
In this case, 44 points are divided into 4 buckets, each of which containing ~11 points. Obviously, in order for each bucket to include the same number of points, they need to have different width of x-values, spanning the quantiles.

After building and training the model, the results doesn't look promising:
<p float="left">
	<img src="https://i.ibb.co/J5c1gW8/download.png" width=345>
	<img src="https://i.ibb.co/qkQ2T3k/download.png" width=345>
</p>
The outcome is not unexpectable, since the data is not linear by any means, and the chosen feature might not be ideal.

&nbsp;
 The prediction of 10 values based on the selected feature is:
 
|Feature value| Label value <br>in thousands \$|Predicted value <br>in thousands \$|
|----         |:----:                          |:----:                             |
|1960         |53                              |179                                |
|3400         |92                              |215                                |
|3677         |69                              |222                                |
|2202         |62                              |185                                |
|2403         |80                              |190                                |
|5652         |295                             |271                                |
|3318         |500                             |213                                |
|2552         |342                             |194                                |
|1364         |118                             |164                                |
|3468         |128                             |217                                |

Most of the predicted values differ highly from the label value, so the trained model probably doesn't have much prediction power. **However**, the first 10 examples might not be representative of the rest of the examples. 

Generally, if the results are bad, then the hyperparameters need to be changed, for example, changing the **feature** used. Although, it can't be any feature, it needs to make sense in terms of loss (for example, if we use `population` the loss is higher).


<u>Useful to know</u>: When the features are changed, other parameters like the Leaning Rate, Number of Epochs and/or Batch Size might need to be reevaluated. 



---
Tags:
[[25-03-2022]], [[Curso]], [[Reuni√£o]]