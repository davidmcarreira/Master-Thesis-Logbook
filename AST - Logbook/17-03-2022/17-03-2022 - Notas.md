# Machine Learning Crash Course - Google 
## Reducing Loss
In order to train a model, loss needs to be reduced. An iterative approach is one widely applied method, being it is easy and efficient.

### An Iterative Approach
Iterative learning is the process of searching for the lowest loss possible by changing the values of the weights, and then apply the model again. It's a trial-and-error process, as suggested by the next image:

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/GradientDescentDiagram.svg">
</p>

Iterative strategies are prevalent in machine learning since their great scalability with large data sets. For a model such as:
$$
y'=b+w_1x_1
$$
 where $y'$ is the predicted output, $b$ is the bias, $w_1$ is the weight and $x_1$ the feature (input). To start minimizing the loss, first random values are attributed to the weight and bias:
 - $b=0$
 - $w_1=0$

If the first value of the feature is 10, then the predicted outcome will be 0. Taking into consideration, the loss function value is computed and new values for $b$ and $w_1$ are generated ("Computer parameter updates" stage in the previous figure).

The learning process continues until the algorithm finds the best model parameters possible that gives the lowest possible loss. Usually, the iteration occurs until the loss stops changing or changes extremely slowly. At that point, it's said that the model **converged**.

### Gradient Descent
<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/convex.svg">
</p>

Convex problems have only one minimum (has seen in the previous figure), but that usually is not the case.

Calculating the loss function for every value of $w_1$ over the entire data set is computationally inconceivable, as sometimes they're constituted by millions (or billions) of entries, rendering the process useless. A better mechanism (very popular in machine learning) is the **gradient descent**.

The first stage in **gradient descent** is to pick a starting point of $w_1$ and work from there (for many algorithms the value itself doesn't really matter, so usually it is set to the trivial value 0 or a random value).

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/GradientDescentStartingPoint.svg">
</p>

The gradient descent algorithm is applied and calculates the gradient of the loss curve, i.e, in what direction does the function vary the most. In this case the last statement is not very useful, but in multidimensional functions it is a very important notion. The **gradient** is a vector of partial derivatives with **respect to the weight**, so it has a **direction** and a **magnitude**.

The gradient will point the direction of the steepest increase (or decrease) in the loss function. Considering a positive gradient will dictate the greatest increase, while a negative gradient will give the greatest decrease, giving name to the algorithm - gradient **descent**.

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/GradientDescentNegativeGradient.svg">
</p>

The next point is calculated by multiplying the previous point's gradient vector by a determined factor (Learning Rate):

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/GradientDescentGradientStep.svg">
</p>

This process is repeated, edging closer to the minimum (where the gradient vector is zero, since the derivative of an extreme is zero).

### Learning Rate
As previously said, the **learning rate** (or step size) is a scalar factor that will lead the algorithm to the next point.

The choice of the learning rate is a very important **hyperparameter** ("tweakable" options in the machine learning algorithm). If it is too big, the minimum can be overshot and oscillate between points; if it's too little, the minimum will never be reached, because as we get closer to it the magnitude of the gradient vector becomes smaller, and smaller resulting and little to no change.
<br>
</br>
<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/LearningRateTooSmall.svg">
</p>

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/LearningRateTooLarge.svg">
</p>

There's a Goldilocks learning rate (that results in an algorithm taking the fewest steps to achieve minimal loss) for every regression (continuous variable prediction) problem that's directly related to how flat the loss function is. If the gradient of the loss function is small, then the learning rate can be larger compared to bigger magnitude gradients without overshooting.

---

###### Ideal Learning Rate (1D)
For one dimensional functions:
$$
\frac{1}{f(x)''}
$$

For 2 or more dimensions, the ideal learning rate is the inverse of the Hessian matrix (square matrix of the second order partial derivatives).
<p align="center">
	<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d2b255c49df2a6e084b9196ab71a68872a739ead" width=300 height="auto">
</p>



For general convex functions, the problem is more complex.

---

### Stochastic Gradient Descent
When performing gradient descent, we already concluded that calculating the loss for every entry in the data set is not feasible. The solution is taking another route for performing the gradient descent. There are several optimization ways, but the most common are: stochastic gradient descent or mini-batch stochastic gradient descent.

Stochastic Gradient Descent (SDG) is when we take just one example at a time (batch with the size of 1), find the new parameters and re-evaluate. The loss is minimized through a stochastic (probability related) method, which doesn't provide guaranteed results regarding the number of steps, but will always be more efficient than performing gradient descent to every example available.

Mini-batch Stochastic Gradient Descent is seen as a compromise between full-batch iteration and Stochastic Gradient Descent. A mini-batch is a portion of the complete data set, compromised of 10 to 1000 examples, chosen at random. Mini-batch reduces the amount of noise in SGD, but is still way more efficient than full-batch iteration.

---
Tags:
[[17-03-2022]], [[Notas]], [[Curso]]