
# Machine Learning - Google Crash Course
## Regularization for Sparsity: $L_1$ Regularization
Feature crosses are very useful, however, they result in more dimensions for our problem. With that, the model can grow too big and consequently so does memory usage cost, and that is a problem.

A good solution would be to drive to **zero** uninformative weights every time it's possible, since it removes completely the corresponding feature, saving RAM and potentially reducing noise in the model.

Previously, we studied $L_2$ regularization, but one of its characteristics is that it **never** drives the weight to exactly zero, so not an option.

There's also $L_0$ regularization, but it's also not an option, as it penalizes the count of non-zero coefficients values and increases the count if there was a sufficient gain in the model's ability to fit the data, that turns a convex optimization to a non-convex optimization problem.

Finally, there's another term, the $L_1$ regularization, that serves the same purpose as $L_0$, but has the advantage of being convex and thus efficient to compute. $L_1$ will drive the less informative weights to zero, reaping RAM savings.

&nbsp;

### $L_1$ vs $L_2$ regularization

The way both terms penalize weights are different:
- $L_2$ penalizes weight $^2$;
- $L_1$ penalizes $\vert$weight$\vert$.

Consequently, they have different derivatives with different meanings:
- Deriving $L_2$ we get $2\times\text{weight}$;
- Deriving $L_1$ is a constant $k$ (and its value is independent of weight).

The derivative of $L_2$ is a multiplier that removes x% of the weight every time, as it gets lower and lower, the percentage is also reduced, resulting in the weight just getting smaller but never zero (ref. [Zeno](https://en.wikipedia.org/wiki/Zeno's_paradoxes#Dichotomy_paradox)).

On another hand, the derivative of $L_1$ is a subtracting constant applied to the weights. Because of the $L_1$ absolute nature, it has a discontinuity at 0, which causes subtraction that cross 0 to be zeroed out. For instance, if a weight is `0.01` and the subtraction forces it to `-0.02`, the regularization term will set it to exactly **zero**.

&nbsp;

### Important notions

- Switching from $L_2$ to $L_1$ regularization drastically reduces the delta between test loss and training loss.
- Switching from $L_2$ to $L_1$ regularization **dampens** all the learned weights.
- Increasing the $L_1$ regularization rate generally dampens the learned weights. **However**, if the rate goes too high, the model can't converge and losses are very high.
- $L_1$ will encourage most of the non-informative weights to be exactly zero. By doing so, those features leave the model. But, it can also **reduce to zero informative weights** that: are weakly informative or strongly informative on different scales and informative features very correlated with other similarly informative features.
- For models with a great number of non-informative features, $L_1$ tends to reduce the number of them, resulting in a reduction of the model size.


&nbsp;


&nbsp;

---
## Neural Networks: Structure
Previously, we studied a way to tackle the non-linearity of some problems - [[06-05-2022 - Notas#Feature Crosses Encoding Nonlinearity|feature crosses]]. A non-linear problem means that a model of the form $b+w_1x_1+w_2x_2$ can't predict a label, i.e, the "decision" is not a line that divides the distribution:

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/NonLinearSpiral.png" width=500>
</p>
	
The previous data can't be solved through a linear model.

A linear model can be modeled as the next graph:
<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/linear_net.svg" width=400>
</p>
Each blue circle is an **input feature**, the arrow is a **weight** and the green circle is the **weighted sum of the inputs**.

&nbsp;

### Hidden Layers
More layers can be added to the model, they're called **Hidden Layers**:

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/1hidden.svg" width=400>
</p>

The yellow dots comprise the newly added layer and are the result of the **weighted sum of the input layer** and the green dot is the **weighted sum of the yellow ones**.

There's no cap to the number of added hidden layers, but the model will remain linear. In order to add non-linearity, another structure must be considered.

&nbsp;

### Activation Functions
To model a non-linear problem, we can directly add non-linearity by routing each hidden layer through a **non-linear function** called **Activation Function**.

<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/activation.svg" width=600>
</p>

Each node in the *Hidden Layer 1* is transformed by the activation function before being passed to the next layer.

&nbsp;

### Common Activation Functions
There are many activation functions, but two of the most used are the **Sigmoid** function and the **Rectified Linear Unit** function, generally called **ReLU**.

#### Sigmoid
The sigmoid converts the **weighted sum** to a value between **0 and 1**.
$$
F(x)=\frac{1}{1+e^{-x}}
$$
<p align="center">
	<img src="https://developers.google.com/machine-learning/crash-course/images/sigmoid.svg" width=400>
</p>

#### Rectified Linear Unit - ReLU
The ReLU works better than a smooth function like the sigmoid and is easier to compute:
$$
F(x)=max(0,x)
$$


### Summary
When we talk about a "neural network", the standard components are:
- A set of nodes, analogous to neurons, organized in layers;
- A set of weights representing connections between each layer;
- A set of biases for each node;
- An activation function that transforms the output of each node in a layer (different layers can have different activation functions).



&nbsp;

&nbsp;

## Introduction to Neural Nets - Exercise
Like usual, we import a dataset composed of a `train_df` to train the model and a `test_df` to test against it.

We then normalize the values by converting them to their Z-scores, so they cover roughly the same range. It also helps the gradient descent to converge more quickly, avoids the "NaN trap" and helps the model to learn more appropriate weights (ref. [[05-05-2022 - Notas#Scaling feature values|Scaling Feature Values]]).

&nbsp;

### Data Representation
The following code creates a **feature layer** containing **3 features**:
- `latitude`X`longitude` (a feature cross);
- `median_income`;
- `population`.

```py
# Create an empty list that will eventually hold all created feature columns.
feature_columns = []


resolution_in_Zs = 0.3 # 3/10 of a standard deviation.


# Create a bucket feature column for latitude.
latitude_as_a_numeric_column = tf.feature_column.numeric_column("latitude")

latitude_boundaries = list(np.arange(int(min(train_df_norm['latitude'])),
int(max(train_df_norm['latitude'])),
resolution_in_Zs))

latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries)


# Create a bucket feature column for longitude.
longitude_as_a_numeric_column = tf.feature_column.numeric_column("longitude")

longitude_boundaries = list(np.arange(int(min(train_df_norm['longitude'])),
int(max(train_df_norm['longitude'])),
resolution_in_Zs))

longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column,
longitude_boundaries)


# Create a feature cross of latitude and longitude.
latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)

crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude)

feature_columns.append(crossed_feature)


# Represent median_income as a floating-point value.
median_income = tf.feature_column.numeric_column("median_income")
feature_columns.append(median_income)


# Represent population as a floating-point value.
population = tf.feature_column.numeric_column("population")
feature_columns.append(population)


# Convert the list of feature columns into a layer that will later be fed into the model.
my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)
```

&nbsp;

### Linear Regression model as a baseline
Before creating a deep neural network, a [**baseline loss**](https://developers.google.com/machine-learning/glossary/#baseline) can be found by running a simple linear regression model that uses the created feature layer.

After creating the model, it is trained:
```py
#Hyperparameters.
learning_rate = 0.01
epochs = 15
batch_size = 1000
label_name = "median_house_value"


#Model's topography.
my_model = create_model(learning_rate, my_feature_layer)


#Train the model on the normalized training set.
epochs, mse = train_model(my_model, train_df_norm, epochs, batch_size, label_name)
plot_the_loss_curve(epochs, mse)


#Evaluate against the test set
test_features = {name:np.array(value) for name, value in test_df_norm.items()}

test_label = np.array(test_features.pop(label_name)) #isolate the label
print("\n Evaluate the linear regression model against the test set:")
my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)
```

The linear regression model, outputs a **baseline loss** of, approximately, `0.3953`.

<p align="center">
	<img src="https://i.ibb.co/GVsGx6X/download.png" width=500>
</p>

Against the **test set**, the loss is `0.3965`.

&nbsp;


### Deep Neural Network model
Now let's create a deep neural network model. The `create_model` function defines the model's topography when specified:
- The number of layers;
- The number of nodes in each layer;
- The activation function.

```py
#Define the first hidden layer with 20 nodes.
model.add(tf.keras.layers.Dense(units=20,
								activation='relu',
								name='Hidden1'))
								
#Define the second hidden layer with 12 nodes.
model.add(tf.keras.layers.Dense(units=12,
								activation='relu',
								name='Hidden2'))
														
#Define the output layer.
model.add(tf.keras.layers.Dense(units=1, name='Output')
```
 
 In the previous code:
 - `units` refers to the number of **nodes** in each layer;
 - `activation` is the **activation function**;
 
&nbsp;

### Deep Training Function
To train the model, we use the `tf.keras.Model.fit` method, it passes a Python dictionary in which the **keys** are the **names of the features** and the **value** of each key is an **array** containing the values of the feature.

To define the training function, we must pay special attention to the following section:

```py
features = {name:np.array(value) for name, value in dataset.items()}
label = np.array(features.pop(label_name))
history = model.fit(x=features, y=label, batch_size=batch_size,
					epochs=epochs, shuffle=True)
```

The training is done with the following code section:
```py
#Hyperparameters.
learning_rate = 0.01
epochs = 20
batch_size = 1000
label_name = "median_house_value"

#Model's topography.
my_model = create_model(learning_rate, my_feature_layer)


#Training for the training set
epochs, mse = train_model(my_model, train_df_norm, epochs,
						  label_name, batch_size)
plot_the_loss_curve(epochs, mse)

#Testing against the test set
test_features = {name:np.array(value) for name, value in 			                  		test_df_norm.items()}
test_label = np.array(test_features.pop(label_name)) # isolate the label
print("\n Evaluate the new model against the test set:")
my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)
```

After training, the loss is `0.3240` (lower than the baseline).

<p align="center">
	<img src="https://i.ibb.co/XZzcFmM/download.png" width=500>
</p>

Against the **test set**, the loss is `0.3634`.

&nbsp;

## Task 1: Compare the two models

Considering that both the models converged during training, we can see that the deep neural network achieved better loss values during training and, most importantly, when evaluated against the test set. Therefore, it is expected that it will make better overall predictions.

## Task 2: Optimize the Neural Network's topography
- Two layers outperform one, but three layers didn't present significant improvements, consequently, there's no need to overload the system with one more layer.
- Relatively to the nodes in each layer:
	- 10 nodes in layer 1;
	- 6 nodes in layer 2.

## Task 3: Regularization
Until this point, 3 methods of regularization have been studied:
- $L_2$ regularization;
- $L_1$ regularization;
- Dropout regularization.

### $L_2$ or $L_1$ regularization
To implement this type of regularization, TensorFlow has 2 methods:
- `tf.keras.regularizers.l2` for $L_2$;
- `tf.keras.regularizers.l1` for $L_1$.

IT will take as parameter the **regularization rate**, `l`. For an $L_2$ reg with a rate of 0.01:
```py
model.add(tf.keras.layers.Dense(units=20,                        		activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l=0.01),
name='Hidden1'))
```

### Dropout regularization
Dropout regularization works by randomly removing unit activations in a network for a single gradient step. The more dropout occurs, the stronger is the regularization. It is implemented as a separate layer in the topography as follows:

```py
model.add(tf.keras.layers.Dense( *define first hidden layer*)
model.add(tf.keras.layers.Dropout(rate=0.25))
model.add(tf.keras.layers.Dense( *define second hidden layer*)
```

The `rate` specifies the fraction of nodes that the model should drop during training.














 



---
Tags:
[[19-05-2022]], [[Curso]], [[Exercícios]]